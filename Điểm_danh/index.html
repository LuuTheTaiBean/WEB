<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Facial Recognition Attendance</title>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <style>
      body {
        font-family: Arial, sans-serif;
        display: flex;
        justify-content: center;
        align-items: center;
        height: 100vh;
        margin: 0;
        background-color: #f4f4f4;
      }
      .container {
        text-align: center;
        background: white;
        padding: 2rem;
        border-radius: 10px;
        box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
      }
      video {
        border: 2px solid #333;
        border-radius: 8px;
        margin-bottom: 1rem;
      }
      canvas {
        position: absolute;
        top: 0;
        left: 0;
      }
      button {
        padding: 0.75rem 1.5rem;
        font-size: 1rem;
        background-color: #007bff;
        color: white;
        border: none;
        border-radius: 5px;
        cursor: pointer;
      }
      button:disabled {
        background-color: #ccc;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>Facial Recognition Attendance</h1>
      <video id="video" width="640" height="480" autoplay></video>
      <canvas id="overlay"></canvas>
      <br />
      <button id="capture" disabled>Mark Attendance</button>
    </div>

    <script>
      const video = document.getElementById("video");
      const canvas = document.getElementById("overlay");
      const captureButton = document.getElementById("capture");
      let faceMatcher;

      Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri("/models"),
        faceapi.nets.faceLandmark68Net.loadFromUri("/models"),
        faceapi.nets.faceRecognitionNet.loadFromUri("/models"),
        faceapi.nets.ssdMobilenetv1.loadFromUri("/models"),
      ]).then(startVideo);

      function startVideo() {
        navigator.mediaDevices
          .getUserMedia({ video: true })
          .then((stream) => {
            video.srcObject = stream;
            captureButton.disabled = false;
          })
          .catch((error) => {
            console.error("Error accessing webcam:", error);
          });
      }

      video.addEventListener("play", () => {
        const displaySize = { width: video.width, height: video.height };
        faceapi.matchDimensions(canvas, displaySize);

        setInterval(async () => {
          const detections = await faceapi
            .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks()
            .withFaceDescriptors();
          const resizedDetections = faceapi.resizeResults(
            detections,
            displaySize
          );

          canvas.getContext("2d").clearRect(0, 0, canvas.width, canvas.height);
          faceapi.draw.drawDetections(canvas, resizedDetections);
          faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
        }, 100);
      });

      captureButton.addEventListener("click", () => {
        alert("Attendance marked! (Facial recognition logic to be expanded)");
      });
    </script>
  </body>
</html>
